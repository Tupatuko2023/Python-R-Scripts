{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work 29: Logistic Regression Analysis on Mortality Using CCI and HFRS: Adjusting for Demographics: \n",
    "# [29.LRM.2.Mortality.CCI.HFRS.Adjusted.V2.ipynb]\n",
    "\n",
    "# \"This notebook performs logistic regression analysis on mortality using CCI and HFRS, \n",
    "#  adjusting for demographics, and saves the processed data.\"\n",
    "\n",
    "########################################################################################################\n",
    "#  Sequence list\n",
    "########################################################################################################\n",
    "# 1: Load the Data: We load the dataset using pd.read_csv().\n",
    "# 2: Ensure 'Potilas_ID' is the same type in all dataframes.\n",
    "# 3: Ensure Columns are Numeric: Convert the CCI and HFRS columns to numeric values, coercing errors to handle any non-numeric data.\n",
    "# 4: Drop Missing Values: Remove any rows that have missing values in either the CCI or HFRS columns to ensure the correlation analysis is accurate.\n",
    "# 5: Merge the demographic data to add gender, birth and dead information.\n",
    "# 6: Create a new column indicating whether an individual is living or deceased.\n",
    "# 7: Define independent variables and the target variable.\n",
    "# 8: Combine X and y to save as one dataframe.\n",
    "# 9: Save the processed data for manual inspection.\n",
    "\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1: Load data\n",
    "data_path = '/home/work/pp_all_data_with_cci.csv'\n",
    "demo_path = '/home/work/demographicd.csv'\n",
    "processed_data_path = '/home/work/processed_data_v6.csv'\n",
    "\n",
    "data = pd.read_csv(data_path, dtype=str)\n",
    "demo_df = pd.read_csv(demo_path, sep='|')\n",
    "\n",
    "print(\"1: Data loaded successfully.\")\n",
    "\n",
    "# 2: Ensure 'Potilas_ID' is the same type in all dataframes\n",
    "data['Potilas_ID'] = data['Potilas_ID'].astype(str)\n",
    "demo_df['Potilas_ID'] = demo_df['Potilas_ID'].astype(str)\n",
    "\n",
    "print(\"2: 'Potilas_ID' is now the same type in all dataframes.\")\n",
    "\n",
    "# 3: Ensure columns are numeric\n",
    "data['CCI'] = pd.to_numeric(data['CCI'], errors='coerce')\n",
    "data['HFRS'] = pd.to_numeric(data['HFRS'], errors='coerce')\n",
    "demo_df['Syntym채vuosi'] = pd.to_numeric(demo_df['Syntym채vuosi'], errors='coerce')\n",
    "\n",
    "print(\"3: Columns are numeric.\")\n",
    "\n",
    "# 4: Drop rows with missing values in CCI or HFRS\n",
    "data = data.dropna(subset=['CCI', 'HFRS'])\n",
    "\n",
    "print(\"4: Missing values dropped.\")\n",
    "\n",
    "# 5: Merge demo_df to add gender, birth and dead information\n",
    "data = data.merge(demo_df[['Potilas_ID', 'Syntym채vuosi', 'Sukupuoli', 'Kuolinvuosi']], on='Potilas_ID', how='left')\n",
    "\n",
    "print(\"5: Gender and demographic information merged successfully.\")\n",
    "\n",
    "# 6: Create a new column indicating whether an individual is living or deceased\n",
    "data['Kuollut'] = data['Kuolinvuosi'].notna().astype(int)\n",
    "\n",
    "print(\"6: Created mortality indicator.\")\n",
    "\n",
    "# 7: Define independent variables and the target variable\n",
    "X = data[['CCI', 'HFRS', 'Syntym채vuosi', 'Sukupuoli']]\n",
    "X = pd.get_dummies(X, columns=['Sukupuoli'], drop_first=True)  # Convert categorical variable to dummy/indicator variables\n",
    "y = data['Kuollut']\n",
    "\n",
    "# 8: Combine X and y to save as one dataframe\n",
    "processed_data = pd.concat([X, y], axis=1)\n",
    "\n",
    "# 9: Save the processed data for manual inspection\n",
    "processed_data.to_csv(processed_data_path, index=False)\n",
    "\n",
    "print(f\"9: Processed data saved to {processed_data_path}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
