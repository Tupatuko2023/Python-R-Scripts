{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860834cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work 7: Combined data [W7.HFRS.1.Combine_data.ipynb] : Creating a new combined dataset\"\n",
    "\n",
    "# Combining and Reshaping Health Diagnoses Data: A Python Jupyter Notebook for Merging and Cleaning\n",
    "\n",
    "# This notebook merges, reshapes, and cleans diagnostic data from two CSV files, removing duplicates and unifying everything into one dataset for analysis and timing.\n",
    "\n",
    "########################################################################################################\n",
    "#  Sequence list\n",
    "########################################################################################################\n",
    "\n",
    "# 1: Define file paths\n",
    "# 2: Select the correct columns\n",
    "# 3: Start the timer\n",
    "# 4: Load data using Pandas and show progress\n",
    "#     4.1: Loading DGN_KAIKKI data\n",
    "#     4.2: Loading KERTOMUS_DGN data\n",
    "# 5: Calculate the number of unique Potilas_ID identifiers in each dataset\n",
    "# 6: Reshape the data into the correct format and show progress\n",
    "#     6.1: Reshaping ef_dg data\n",
    "#     6.2: Reshaping ef_dg2 data\n",
    "# 7: Print the number of rows in the reshaped datasets\n",
    "# 8: Combine all DataFrames into one using Pandas\n",
    "# 9: Print the number of rows in the combined dataset\n",
    "# 10: Remove duplicates and save the results using Pandas\n",
    "# 11: Print the final number of rows in the dataset\n",
    "# 12: Stop the timer and show the execution time\n",
    "# 13: Print the number of unique Potilas_ID identifiers in the merged dataset\n",
    "\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# 1: Define file paths\n",
    "ef_dg_path = '/home/work/dataset1.csv'\n",
    "ef_dg2_path = '/home/work/dataset2.csv'\n",
    "output_path =  '/home/work/all_data.csv'\n",
    "\n",
    "print(\"1: File paths defined\")\n",
    "\n",
    "# 2: Select the correct columns\n",
    "ef_dg_columns = ['Potilas_ID', 'pvm', 'koodi1', 'koodi2']\n",
    "ef_dg2_columns = ['Tunniste', 'pvm', 'koodi1']\n",
    "\n",
    "print(\"2: Correct columns selected\")\n",
    "\n",
    "# 3: Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# 4: Load data using Pandas and show progress\n",
    "print(\"4.1: Loading DGN_KAIKKI data...\")\n",
    "ef_dg_df = pd.read_csv(ef_dg_path, sep='|', usecols=ef_dg_columns)\n",
    "\n",
    "print(\"4.2: Loading KERTOMUS_DGN data...\")\n",
    "ef_dg2_df = pd.read_csv(ef_dg2_path, sep='|', usecols=ef_dg2_columns)\n",
    "\n",
    "# 5: Calculate the number of unique Potilas_ID identifiers in each dataset\n",
    "unique_ef_dg = ef_dg_df['Potilas_ID'].nunique()\n",
    "unique_ef_dg2 = ef_dg2_df['Tunniste'].nunique()\n",
    "combined_unique_ids = pd.concat([ef_dg_df['Potilas_ID'], ef_dg2_df['Tunniste']]).nunique()\n",
    "\n",
    "print(f\"5a: Unique Potilas_ID identifiers in ef_dg data: {unique_ef_dg}\")\n",
    "print(f\"5b: Unique Potilas_ID identifiers in ef_dg2 data: {unique_ef_dg2}\")\n",
    "print(f\"5d: Total unique Potilas_ID identifiers before merging: {combined_unique_ids}\")\n",
    "\n",
    "# 6: Reshape the data into the correct format and show progress\n",
    "print(\"6.1: Reshaping ef_dg data...\")\n",
    "ef_dg_df_melted = ef_dg_df.melt(\n",
    "    id_vars=['Potilas_ID'], \n",
    "    value_vars=['koodi1', 'koodi2'], \n",
    "    value_name='ICD_code'\n",
    ").dropna(subset=['ICD_code'])\n",
    "\n",
    "print(\"6.2: Reshaping ef_dg2 data...\")\n",
    "ef_dg2_df_melted = ef_dg2_df.rename(columns={'koodi1': 'ICD_code'}).dropna(subset=['ICD_code'])\n",
    "\n",
    "# 7: Print the number of rows in the reshaped datasets\n",
    "print(f\"ef_dg melted data rows: {len(ef_dg_df_melted)}\")\n",
    "print(f\"ef_dg2 melted data rows: {len(ef_dg2_df_melted)}\")\n",
    "\n",
    "# 8: Combine all DataFrames into one using Pandas\n",
    "print(\"8: Combining data...\")\n",
    "all_data = pd.concat([ef_dg_df_melted, ef_dg2_df_melted])\n",
    "\n",
    "# 9: Print the number of rows in the combined dataset\n",
    "print(f\"Combined data rows: {len(all_data)}\")\n",
    "\n",
    "# 10: Remove duplicates and save the results using Pandas\n",
    "print(\"10: Removing duplicates and saving results...\")\n",
    "all_data = all_data.drop_duplicates()\n",
    "all_data.to_csv(output_path, index=False)\n",
    "\n",
    "# 11: Print the final number of rows in the dataset\n",
    "print(f\"Final data rows after removing duplicates: {len(all_data)}\")\n",
    "\n",
    "# 12: Stop the timer and show the execution time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"12: Merged data saved to path: {output_path}\")\n",
    "print(f\"Process took {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "# 13: Print the number of unique Potilas_ID identifiers in the merged dataset\n",
    "unique_patient_ids = all_data['Potilas_ID'].nunique()\n",
    "print(f\"13: Unique Potilas_ID identifiers in the merged dataset: {unique_patient_ids}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
